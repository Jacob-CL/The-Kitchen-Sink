{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "url = \"http://83.136.255.150\"\n",
    "short_url = \"83.136.255.150\"\n",
    "url2 = \"https://www.google.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [4.1 Information Gathering](https://owasp.org/www-project-web-security-testing-guide/stable/4-Web_Application_Security_Testing/01-Information_Gathering/README)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [4.1.1 Conduct Search Engine Discovery Reconnaissance for Information Leakage](https://owasp.org/www-project-web-security-testing-guide/stable/4-Web_Application_Security_Testing/01-Information_Gathering/01-Conduct_Search_Engine_Discovery_Reconnaissance_for_Information_Leakage)\n",
    "\n",
    "The goal is to identify what sensitive design and configuration information of the application, system, or organization is exposed directly (on the organization’s website) or indirectly (via third-party services).\n",
    "\n",
    "- [Google Hacking Database](https://www.exploit-db.com/google-hacking-database)\n",
    "- [Google Hacking Diggity Project](https://resources.bishopfox.com/resources/tools/google-hacking-diggity/)\n",
    "- [Vulnerability Assessment.co.uk/PenetrationTest.html](vulnerabilityassessment.co.uk/Penetration%20Test.html)\n",
    "- [SecuritySift/passive-reconnaissance](securitysift.com/passive-reconnaissance/)\n",
    "- [PentestStandard.org/IntelligenceGathering](pentest-standard.org/index.php/Intelligence_Gathering)\n",
    "- [Onstrat.com/OSINT](onstrat.com/osint/)\n",
    "\n",
    "\n",
    "## Tools\n",
    "\n",
    "| Relationship and Recon Tools            | Name               |\n",
    "|-----------------------------------------|--------------------|\n",
    "| github.com/ElevenPaths/FOCA             | FOCA               |\n",
    "| github.com/laramies/theHarvester        | theHarvester       |\n",
    "| maltego.com                             | Maltego            |\n",
    "| https://github.com/lanmaster53/recon-ng | Recon-ng Framework |\n",
    "|                                         |                    |\n",
    "\n",
    "\n",
    "## Network\n",
    "\n",
    "| Network Resource                    | Website                               |\n",
    "|-------------------------------------|---------------------------------------|\n",
    "| DNSstuff Toolbox                    | [dnsstuff.com/tools](https://dnsstuff.com/tools) |\n",
    "| Network-Tools                       | [network-tools.com](http://network-tools.com) | \n",
    "| CentralOps                          | [centralops.net](http://centralops.net) |\n",
    "| Hurricane Electric                  | [lg.he.net](http://lg.he.net)         |\n",
    "| BGP                                 | [bgp4.as/looking-glasses](http://bgp4.as/looking-glasses) |\n",
    "| Shodan                              | [shodan.io](http://shodan.io)         |\n",
    "| GreyNoise                           | [viz.greynoise.io](http://viz.greynoise.io) |\n",
    "| MxToolBox                           | [mxtoolbox.com/NetworkTools.aspx](http://mxtoolbox.com/NetworkTools.aspx) |\n",
    "| IANA IP and ASN Lookup              | [iana.org/numbers](http://iana.org/numbers) |\n",
    "\n",
    "\n",
    "## WHOIS\n",
    "\n",
    "| WHOIS Resource | Website               |\n",
    "|----------------|-----------------------|\n",
    "| ICANN          | [icann.org](https://icann.org) |\n",
    "| IANA           | [iana.com](https://iana.com)   |\n",
    "| NRO            | [nro.net](https://nro.net)     |\n",
    "| AFRINIC        | [afrinic.net](https://afrinic.net) |\n",
    "| APNIC          | [apnic.net](https://apnic.net) |\n",
    "| ARIN           | [ws.arin.net](https://ws.arin.net) |\n",
    "| LACNIC         | [lacnic.net](https://lacnic.net) |\n",
    "| RIPE           | [ripe.net](https://ripe.net)   |\n",
    "| InterNIC       | [internic.net](https://internic.net) |\n",
    "\n",
    "## Search engines\n",
    "\n",
    "| Search Engine Name               | Description                                                                                           |\n",
    "|----------------------------------|-------------------------------------------------------------------------------------------------------|\n",
    "| Baidu                            | China’s most popular search engine.                                                                   |\n",
    "| Bing                             | A search engine owned and operated by Microsoft, and the second most popular worldwide. Supports advanced search keywords. |\n",
    "| binsearch.info                   | A search engine for binary Usenet newsgroups.                                                         |\n",
    "| Common Crawl                     | \"An open repository of web crawl data that can be accessed and analyzed by anyone.\"                   |\n",
    "| DuckDuckGo                       | A privacy-focused search engine that compiles results from many different sources. Supports search syntax. |\n",
    "| Google                           | Offers the world’s most popular search engine, and uses a ranking system to attempt to return the most relevant results. Supports search operators. |\n",
    "| Internet Archive Wayback Machine | \"Building a digital library of Internet sites and other cultural artifacts in digital form.\"           |\n",
    "| Startpage                        | A search engine that uses Google’s results without collecting personal information through trackers and logs. Supports search operators. |\n",
    "| Shodan                           | A service for searching Internet-connected devices and services. Usage options include a limited free plan as well as paid subscription plans. |\n",
    "\n",
    "\n",
    "## Google Searching\n",
    "\n",
    "| Google Searches                        | Description                          |\n",
    "|----------------------------------------|--------------------------------------|\n",
    "| site:<URL>                             | Search only one                      |\n",
    "| numrange:<START_NUMBER>...<END_NUMBER> | Search within a number range         |\n",
    "| date:<INTEGER>                         | Search within past [#] months        |\n",
    "| link:<URL>                             | Find pages that link to given URL    |\n",
    "| related:<URL>                          | Find pages related to given URL      |\n",
    "| intitle:<STRING>                       | Find pages with <STRING> in title    |\n",
    "| inbody: / intext:                      | Only search for the keyword in the body of pages |\n",
    "| inurl:<STRING>                         | Find pages with <STRING> in URL      |\n",
    "| filetype:<EXTENSION>                   | Search for files by filetype         |\n",
    "| phonebook:<STRING>                     | Find phone book listings of <STRING> |\n",
    "| cache:<STRING>                         | Search for conent that has previously been indexed |\n",
    "|                                        |                                      |\n",
    "\n",
    "\n",
    "## People Searching Tools\n",
    "\n",
    "| Tool                           |                |\n",
    "|--------------------------------|----------------|\n",
    "| peekyou.com                    | PeekYou        | \n",
    "| spokeo.com                     | Spokeo         | \n",
    "| pipl.com                       | pipl.com       | \n",
    "| intelius.com                   | Intelius       | \n",
    "| publicrecords.searchsystem.net | Search Systems | \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [4.1.2 Fingerprint Web Server](https://owasp.org/www-project-web-security-testing-guide/stable/4-Web_Application_Security_Testing/01-Information_Gathering/02-Fingerprint_Web_Server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the version and type of a running web server to enable further discovery of any known vulnerabilities.\n",
    "\n",
    "import socket\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def banner_grab(url):\n",
    "    # Parse the URL to extract the domain and possible port\n",
    "    parsed_url = urlparse(url)\n",
    "    domain = parsed_url.netloc.split(':')[0]  # Get the domain without the port\n",
    "    port = parsed_url.port if parsed_url.port else 80  # Use port 80 if no port specified\n",
    "\n",
    "    def send_request(request):\n",
    "        try:\n",
    "            # Create a socket object\n",
    "            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "            s.settimeout(10)  # Set timeout for the socket\n",
    "            # Connect to the server\n",
    "            s.connect((domain, port))\n",
    "            # Send the HTTP request to the server\n",
    "            s.send(request.encode())\n",
    "            # Receive the response from the server\n",
    "            response = s.recv(4096)  # Adjust size as necessary\n",
    "            s.close()  # Always close the socket\n",
    "            # Decode and split the response at the first double newline, which ends the headers\n",
    "            headers, _, _ = response.decode().partition('\\r\\n\\r\\n')\n",
    "            return headers\n",
    "        except Exception as e:\n",
    "            return f\"Failed to connect or retrieve data: {e}\"\n",
    "        \n",
    "\n",
    "    # Standard HTTP GET request\n",
    "    normal_request = f\"GET / HTTP/1.1\\r\\nHost: {domain}\\r\\nConnection: close\\r\\n\\r\\n\"\n",
    "    headers = send_request(normal_request)\n",
    "    print(f\"\"\"\n",
    "--> BANNER GRABBING {url}\n",
    "================================================================================\n",
    "\n",
    "> Normal GET request sent:\\n{normal_request}\n",
    "> Normal GET request response:\\n{headers}\n",
    "--------------------------------------------------------------------------------\"\"\")\n",
    "\n",
    "\n",
    "    # Malformed GET request with non-existent method 'FAKE'\n",
    "    malformed_request = f\"GET / FAKE/1.1\\r\\nHost: {domain}\\r\\nConnection: close\\r\\n\\r\\n\"\n",
    "    headers = send_request(malformed_request)\n",
    "    print(f\"\"\"\n",
    "> Malformed GET request sent with non-existent protocol 'FAKE':\\n{malformed_request}\n",
    "> Malformed GET request reponse:\\n{headers}\n",
    "--------------------------------------------------------------------------------\"\"\")\n",
    "\n",
    "\n",
    "    # Malformed request with non-existent method 'FAKE'\n",
    "    malformed_request = f\"FAKE / HTTP/1.1\\r\\nHost: {domain}\\r\\nConnection: close\\r\\n\\r\\n\"\n",
    "    headers = send_request(malformed_request)\n",
    "    print(f\"\"\"\n",
    "> Malformed FAKE request sent with non-existent method 'FAKE':\\n{malformed_request}\n",
    "> Malformed FAKE request response:\\n{headers}\n",
    "--------------------------------------------------------------------------------\"\"\")\n",
    "    \n",
    "    # Different HTTP versions\n",
    "    malformed_request = f\"GET / HTTP/1.0\\r\\nHost: {domain}\\r\\nConnection: close\\r\\n\\r\\n\"\n",
    "    headers = send_request(malformed_request)\n",
    "    print(f\"\"\"\n",
    "> HTTP version 1.0 request sent:\\n{malformed_request}\n",
    "> HTTP version 1.0 request response:\\n{headers}\n",
    "--------------------------------------------------------------------------------\"\"\")\n",
    "    \n",
    "    # Different HTTP versions\n",
    "    malformed_request = f\"GET / HTTP/2.0\\r\\nHost: {domain}\\r\\nConnection: close\\r\\n\\r\\n\"\n",
    "    headers = send_request(malformed_request)\n",
    "    print(f\"\"\"\n",
    "> HTTP version 2.0 request sent:\\n{malformed_request}\n",
    "> HTTP version 2.0 request response:\\n{headers}\n",
    "--------------------------------------------------------------------------------\"\"\")\n",
    "    \n",
    "banner_grab(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [4.1.3 Review Webserver Metafiles for Information Leakage](https://owasp.org/www-project-web-security-testing-guide/stable/4-Web_Application_Security_Testing/01-Information_Gathering/03-Review_Webserver_Metafiles_for_Information_Leakage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify hidden or obfuscated paths and functionality through the analysis of metadata files.\n",
    "# Extract and map other information that could lead to better understanding of the systems at hand.\n",
    "\n",
    "databases = ['MySQL','Mongo'',MSSQL','noSQL','postgreSQL']\n",
    "frontend_filtering = ['dompurify','caja','sanitize','filter','addslashes','blacklist','black-list','black list', 'whitelist', 'white-list', 'white list']\n",
    "html_comments = ['<!--']\n",
    "html_inputs = ['<input','<textarea','<form']\n",
    "html_meta_tags = ['<meta']\n",
    "javascript_tags = ['<script']\n",
    "\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "\n",
    "# Function to check a URL and return its status code\n",
    "def get_url_status_code(url):\n",
    "    try:\n",
    "        response = requests.head(url, timeout=5)\n",
    "        return response.status_code\n",
    "    except requests.RequestException:\n",
    "        return None  # Return None if there was an error making the request\n",
    "\n",
    "print(\"\\n--> Enumerating URL by checking for all response codes less than 400...\\n\")\n",
    "\n",
    "# Hardcoded list of paths\n",
    "paths = [\n",
    "    '/',\n",
    "    '/nonexistentpage',\n",
    "    '/home',\n",
    "    '/about',\n",
    "    '/contact',\n",
    "    '/login',\n",
    "    '/search',\n",
    "    '/register',\n",
    "    '/signup',\n",
    "    '/blog',\n",
    "    '/faq',\n",
    "    '/products',\n",
    "    '/services',\n",
    "    '/profile',\n",
    "    '/settings',\n",
    "    '/terms',\n",
    "    '/help',\n",
    "    '/privacy',\n",
    "    '/account',\n",
    "    '/robots.txt',\n",
    "    '/index.html',\n",
    "    '/humans.txt',\n",
    "    '/sitemap.xml',\n",
    "    '/security.txt',\n",
    "    '/.well-known/security.txt',\n",
    "    '/.well-known/'\n",
    "]\n",
    "\n",
    "valid_urls = []\n",
    "# Iterate over the hardcoded paths and check each one\n",
    "for path in paths:\n",
    "    # Construct the full URL\n",
    "    extended_url = urljoin(url, path)\n",
    "\n",
    "    # Get the status code for the URL\n",
    "    status_code = get_url_status_code(extended_url)\n",
    "\n",
    "    # Determine if the URL is valid based on the status code\n",
    "    if status_code is not None and status_code < 400:\n",
    "        print(f\"{status_code} - Valid URL: {extended_url}\")\n",
    "        valid_urls.append(extended_url)  # Add the valid URL to the list\n",
    "    else:\n",
    "        # If status_code is None, it means the request failed\n",
    "        if status_code is None:\n",
    "            print(f\"Error making request to: {extended_url}\")\n",
    "        else:\n",
    "            print(f\"{status_code} ---- XX Invalid URL: {extended_url}\")\n",
    "\n",
    "print(f\"\\n✓✓ Enumeration on {url} complete. \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [4.1.4 Enumerate Applications on WebServer](https://owasp.org/www-project-web-security-testing-guide/stable/4-Web_Application_Security_Testing/01-Information_Gathering/04-Enumerate_Applications_on_Webserver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerate the applications within scope that exist on a web server, relatively manual process. Read link ^ \n",
    "import nmap\n",
    "import dns.resolver\n",
    "import socket\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Create an Nmap PortScanner object\n",
    "nm = nmap.PortScanner()\n",
    "\n",
    "# List of common ports to scan\n",
    "common_ports = [\n",
    "    '21',    # FTP\n",
    "    '22',    # SSH\n",
    "    '23',    # Telnet\n",
    "    '25',    # SMTP\n",
    "    '53',    # DNS\n",
    "    '80',    # HTTP\n",
    "    '110',   # POP3\n",
    "    '143',   # IMAP\n",
    "    '443',   # HTTPS\n",
    "    '1433',  # MSSQL\n",
    "    '3306',  # MySQL\n",
    "    '3389',  # RDP\n",
    "    '8080'   # HTTP alternative\n",
    "]\n",
    "\n",
    "try:\n",
    "    print(\"--> Performing NMAP scan on common ports with verbose output, returning only open ports..\\n\")\n",
    "    # Convert the list of common ports into a comma-separated string for Nmap\n",
    "    ports = ','.join(common_ports)\n",
    "    # Run the scan with service and version detection\n",
    "    nm.scan(url, ports, arguments='-sV -O')  # Including service detection and OS detection\n",
    "\n",
    "    if nm.all_hosts():  # Check if any hosts were found\n",
    "        for host in nm.all_hosts():  # Loop through all hosts\n",
    "            print(f'Host : {host} ({nm[host].hosturl()})')\n",
    "            print(f'State : {nm[host].state()}')\n",
    "\n",
    "            # Loop through all scanned protocols and corresponding ports\n",
    "            for proto in nm[host].all_protocols():\n",
    "                print('----------')\n",
    "                print(f'Protocol : {proto}')\n",
    "\n",
    "                lport = nm[host][proto].keys()\n",
    "                for port in sorted(lport):\n",
    "                    port_info = nm[host][proto][port]\n",
    "                    # Print detailed information for each port\n",
    "                    if port_info[\"state\"] == \"open\":\n",
    "                        print(f'Port : {port}\\tState : {port_info[\"state\"]}')\n",
    "                        if 'url' in port_info:\n",
    "                            print(f'\\tService : {port_info[\"url\"]}')\n",
    "                        if 'product' in port_info:\n",
    "                            print(f'\\tProduct : {port_info[\"product\"]}')\n",
    "                        if 'version' in port_info:\n",
    "                            print(f'\\tVersion : {port_info[\"version\"]}')\n",
    "                        if 'extrainfo' in port_info:\n",
    "                            print(f'\\tExtra Info : {port_info[\"extrainfo\"]}')\n",
    "                        if 'script' in port_info:\n",
    "                            print(f'\\tScripts : {port_info[\"script\"]}')\n",
    "    else:\n",
    "        print(\"No hosts found. Ensure the IP address or hosturl is correctly specified.\")\n",
    "except Exception as e:\n",
    "    print(f\"Scan error: {e}\")\n",
    "\n",
    "\n",
    "# print(\"\\n--> Quick scanning the first 1024 ports..\\n\")\n",
    "# try:\n",
    "#     # Run a simple Nmap scan\n",
    "#     nm.scan(url, '1-1024')  # Scans TCP ports 1 through 1024\n",
    "#     if nm.all_hosts():  # Check if any hosts were found\n",
    "#         for host in nm.all_hosts():  # Loop through all hosts\n",
    "#             print('Host : %s (%s)' % (host, nm[host].hosturl()))  # Get the host and its hosturl\n",
    "#             print('State : %s' % nm[host].state())  # Get the state of the host (up/down)\n",
    "\n",
    "#             # Loop through all scanned protocols and corresponding ports\n",
    "#             for proto in nm[host].all_protocols():\n",
    "#                 print('----------')\n",
    "#                 print('Protocol : %s' % proto)\n",
    "\n",
    "#                 lport = nm[host][proto].keys()\n",
    "#                 for port in sorted(lport):\n",
    "#                     # Print port and state\n",
    "#                     print('port : %s\\tstate : %s' % (port, nm[host][proto][port]['state']))\n",
    "#     else:\n",
    "#         print(\"No hosts found.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Scan error: {e}\")\n",
    "\n",
    "print(\"\\n--> Trying for more DNS information..\\n\")\n",
    "# Get More Detailed DNS Information\n",
    "def dns_lookup(url, record_type):\n",
    "    try:\n",
    "        # Perform the DNS query\n",
    "        response = dns.resolver.resolve(url, record_type)\n",
    "        \n",
    "        # Print details about the DNS response\n",
    "        print(f\"Query for {url} {record_type} records:\")\n",
    "        for answer in response:\n",
    "            print(f\"  - {record_type} record: {answer.to_text()}\")\n",
    "            print(f\"    TTL: {answer.ttl} seconds\")\n",
    "        \n",
    "        # Print additional response information\n",
    "        print(\"\\nAdditional response metadata:\")\n",
    "        print(f\"  Query time: {response.response.time * 1000:.2f} ms\")\n",
    "        print(f\"  urlservers used for the query:\")\n",
    "        for ns in response.urlservers:\n",
    "            print(f\"    {ns}\")\n",
    "        \n",
    "    except dns.resolver.NoAnswer:\n",
    "        print(f\"No {record_type} record found for {url}\")\n",
    "    except dns.resolver.NXDOMAIN:\n",
    "        print(f\"The domain {url} does not exist\")\n",
    "    except dns.resolver.Timeout:\n",
    "        print(\"The request timed out\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "dns_lookup(url, 'A')  # A record lookup\n",
    "dns_lookup(url, 'MX')  # MX record lookup\n",
    "dns_lookup(url, 'NS')  # NS record lookup\n",
    "\n",
    "def get_ip_address(url):\n",
    "    print(\"\\n--> Trying to get IP address..\\n\")\n",
    "    try:\n",
    "        # Extract the hostname from the URL\n",
    "        hostname = urlparse(url).hostname\n",
    "        # Resolve the hostname to an IP address\n",
    "        ip_address = socket.gethostbyname(hostname)\n",
    "        print(f\"The IP address of {url} is {ip_address}\")\n",
    "    except socket.error as err:\n",
    "        print(f\"Error: {err}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "get_ip_address(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
